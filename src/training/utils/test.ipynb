{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3680693412.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[26], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(line[1])1\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "tweets = []\n",
    "classes = []\n",
    "for line in open('/Users/ikea/Documents/Brown/course/CS2470/Hate Speech Detection/data/training_data/offenseval-training-v1.tsv','r',encoding='ISO-8859-1'):\n",
    "    line = re.sub(r'#([^ ]*)', r'\\1', line)\n",
    "    line = re.sub(r'https.*[^ ]', 'URL', line)\n",
    "    line = re.sub(r'http.*[^ ]', 'URL', line)\n",
    "    line = emoji.demojize(line)\n",
    "    line = re.sub(r'(:.*?:)', r' \\1 ', line)\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    line = line.rstrip('\\n').split('\\t')\n",
    "    print(line[1])1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Mustinefustine @malopedia Je suis sans voix â...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Pour rÃ :copyright: sumer, Greg Pak a eu le b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BONJOUR ! je suis crevÃ :copyright: ALED | HÃ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sergio_coma Nn Ã§a meuf c jenre une noich ou ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"SoirÃ :copyright: e crÃ¨ve-cÅurÂ : comment c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Faut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>en envoyant le Raid et le GIGN en Guadeloupe, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>\"@morandini_live @stephanetiki @AmezianeRose @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>\"Contactez Jonathan Noel\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>\"Des substitutions de personnes (v. utilisatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     @Mustinefustine @malopedia Je suis sans voix â...      0\n",
       "1     \"Pour rÃ :copyright: sumer, Greg Pak a eu le b...      1\n",
       "2     BONJOUR ! je suis crevÃ :copyright: ALED | HÃ ...      0\n",
       "3     @sergio_coma Nn Ã§a meuf c jenre une noich ou ...      1\n",
       "4     \"SoirÃ :copyright: e crÃ¨ve-cÅurÂ : comment c...      0\n",
       "...                                                 ...    ...\n",
       "2279  @tical10 @ExBarcaFan74523 @ConflitsFrance Faut...      0\n",
       "2280  en envoyant le Raid et le GIGN en Guadeloupe, ...      1\n",
       "2281  \"@morandini_live @stephanetiki @AmezianeRose @...      0\n",
       "2282                         \"Contactez Jonathan Noel\\n      0\n",
       "2283  \"Des substitutions de personnes (v. utilisatio...      0\n",
       "\n",
       "[2284 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "data = pd.read_csv('/Users/ikea/Documents/Brown/course/CS2470/Hate Speech Detection/data/french_train.csv')\n",
    "# Remove the hash symbol (#) from hashtags\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'#([^ ]*)', r'\\1', x))\n",
    "# Replace URLs with 'URL'\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'https?://\\S+', 'URL', x))\n",
    "# Convert emojis to their textual representation\n",
    "data['text'] = data['text'].apply(emoji.demojize)\n",
    "# Ensure spaces around emoji textual representations\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'(:[^:\\s]+:)', r' \\1 ', x))\n",
    "# Normalize multiple spaces to a single space\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Mustinefustine @malopedia Je suis sans voix â...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Pour rÃ©sumer, Greg Pak a eu le bon goÃ»t de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BONJOUR ! je suis crevÃ© ALED | HÃ©sitez pas Ã...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sergio_coma Nn Ã§a meuf c jenre une noich ou ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"SoirÃ©e crÃ¨ve-cÅurÂ : comment choisir entre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Faut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>en envoyant le Raid et le GIGN en Guadeloupe, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>\"@morandini_live @stephanetiki @AmezianeRose @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>\"Contactez Jonathan Noel\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>\"Des substitutions de personnes (v. utilisatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     @Mustinefustine @malopedia Je suis sans voix â...      0\n",
       "1     \"Pour rÃ©sumer, Greg Pak a eu le bon goÃ»t de ...      1\n",
       "2     BONJOUR ! je suis crevÃ© ALED | HÃ©sitez pas Ã...      0\n",
       "3     @sergio_coma Nn Ã§a meuf c jenre une noich ou ...      1\n",
       "4     \"SoirÃ©e crÃ¨ve-cÅurÂ : comment choisir entre...      0\n",
       "...                                                 ...    ...\n",
       "2279  @tical10 @ExBarcaFan74523 @ConflitsFrance Faut...      0\n",
       "2280  en envoyant le Raid et le GIGN en Guadeloupe, ...      1\n",
       "2281  \"@morandini_live @stephanetiki @AmezianeRose @...      0\n",
       "2282                         \"Contactez Jonathan Noel\\n      0\n",
       "2283  \"Des substitutions de personnes (v. utilisatio...      0\n",
       "\n",
       "[2284 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/ikea/Documents/Brown/course/CS2470/Hate Speech Detection/data/french_train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ikea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  @Mustinefustine @malopedia Je suis sans voix â...   \n",
      "1  \"Pour rÃ©sumer, Greg Pak a eu le bon goÃ»t de ...   \n",
      "2  BONJOUR ! je suis crevÃ© ALED | HÃ©sitez pas Ã...   \n",
      "3  @sergio_coma Nn Ã§a meuf c jenre une noich ou ...   \n",
      "4  \"SoirÃ©e crÃ¨ve-cÅurÂ : comment choisir entre...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [@, mustinefustine, @, malopedia, je, suis, sa...  \n",
      "1  [``, pour, rã©sumer, ,, greg, pak, a, eu, le, ...  \n",
      "2  [bonjour, !, je, suis, crevã©, aled, |, hã©sit...  \n",
      "3  [@, sergio_coma, nn, ã§a, meuf, c, jenre, une,...  \n",
      "4  [``, soirã©e, crã¨ve-cåurâ, :, comment, chois...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "def preprocess_and_tokenize(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "data = pd.read_csv('/Users/ikea/Documents/Brown/course/CS2470/Hate Speech Detection/data/french_train.csv')\n",
    "# Applying preprocessing and tokenization to each text entry in the DataFrame\n",
    "data['tokens'] = data['text'].apply(preprocess_and_tokenize)\n",
    "\n",
    "# Display the tokenized data\n",
    "print(data[['text', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470 Python 3.9.15",
   "language": "python",
   "name": "csci1470"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
